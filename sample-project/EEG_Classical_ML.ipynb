{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID => This identifies the column name in your dataset that contains a unique identifier for each sample.\n",
    "ID = [\"ID\"]\n",
    "TARGET = [\"predefinedlabel\"] # Label or output you're trying to predict.\n",
    "FEATURES = [\"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "\n",
    "# A random seed ensures reproducibility.\n",
    "SEED = 5412\n",
    "\n",
    "# the number of samples to be used for training.\n",
    "NUM_TRAIN_SAMPLES = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "- `SubjectID` = identifies each participant.\n",
    "- `VideoID` = identifies each video stimulus shown to participants.\n",
    "- `np.unique(data[\"VideoID\"])` = counts how many unique videos there are.\n",
    "- `len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]` = generates a unique number for each combination of subject and video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Delta     Theta    Alpha1   Alpha2    Beta1     Beta2   Gamma1  \\\n",
       "0   0  301963.0   90612.0   33735.0  23991.0  27946.0   45097.0  33228.0   \n",
       "1   0   73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   5293.0   \n",
       "2   0  758353.0  383745.0  201999.0  62107.0  36293.0  130536.0  57243.0   \n",
       "\n",
       "    Gamma2  predefinedlabel  \n",
       "0   8293.0              0.0  \n",
       "1   2740.0              0.0  \n",
       "2  25354.0              0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"EEG_data.csv\")\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "\n",
    "data = data[ID + FEATURES + TARGET] # Keep the needed column\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape_dataset() - converts raw dataframe into\n",
    "# X: 2D numpy array → each row = one trial (flattened features)\n",
    "# y: 1D array of class labels for each trial\n",
    "\n",
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()): # Loops over each unique ID (i.e., each trial)\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id] # Selects all rows corresponding to the current trial\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\")) # Take the mean of the target\n",
    "        features.append(cur_id_data[FEATURES].to_numpy()) # Appends the feature matrix for this trial (rows × EEG bands)\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features).reshape(features.shape[0], -1), np.array(target)\n",
    "\n",
    "\n",
    "# EEG trials may vary in length (e.g., one trial has 5 rows, another has 7),\n",
    "# but ML models expect equal-sized inputs.\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    # Pads shorter trials with zeros so all have the same number of rows.\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    # Finds the longest trial (in terms of number of rows/time windows)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    # Pads each array with zeros at the bottom to make it as long as max_length.\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8870, 10)\n",
      "Test shape: (3941, 10)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "unique_ids = np.unique(np.ravel(data[ID]))\n",
    "train_id = np.random.choice(unique_ids, NUM_TRAIN_SAMPLES, replace=False)\n",
    "train_index = np.isin(data[ID], train_id)\n",
    "\n",
    "train = data.iloc[train_index].copy()\n",
    "test = data.iloc[~train_index].copy()\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.487284</td>\n",
       "      <td>-0.325816</td>\n",
       "      <td>-0.110513</td>\n",
       "      <td>-0.154594</td>\n",
       "      <td>0.106498</td>\n",
       "      <td>0.193042</td>\n",
       "      <td>0.113539</td>\n",
       "      <td>-0.179235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.843171</td>\n",
       "      <td>-0.588248</td>\n",
       "      <td>-0.564010</td>\n",
       "      <td>-0.537349</td>\n",
       "      <td>-0.593586</td>\n",
       "      <td>-0.470878</td>\n",
       "      <td>-0.334422</td>\n",
       "      <td>-0.362733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.904453</td>\n",
       "      <td>2.252233</td>\n",
       "      <td>0.516136</td>\n",
       "      <td>0.338387</td>\n",
       "      <td>1.562871</td>\n",
       "      <td>0.498640</td>\n",
       "      <td>0.384545</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Delta     Theta    Alpha1    Alpha2     Beta1     Beta2    Gamma1  \\\n",
       "0   0 -0.487284 -0.325816 -0.110513 -0.154594  0.106498  0.193042  0.113539   \n",
       "1   0 -0.843171 -0.588248 -0.564010 -0.537349 -0.593586 -0.470878 -0.334422   \n",
       "2   0  0.224548  0.904453  2.252233  0.516136  0.338387  1.562871  0.498640   \n",
       "\n",
       "     Gamma2  predefinedlabel  \n",
       "0 -0.179235              0.0  \n",
       "1 -0.362733              0.0  \n",
       "2  0.384545              0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train[FEATURES] = scaler.fit_transform(train[FEATURES])\n",
    "test[FEATURES] = scaler.transform(test[FEATURES])\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train shapes: ((70, 1152), (70,))\n",
      "Reshaped Test shapes: ((30, 1152), (30,))\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = reshape_dataset(train)\n",
    "X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "print(f\"Reshaped Train shapes: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Reshaped Test shapes: {X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48728418 -0.32581625 -0.11051269 -0.15459446  0.10649789  0.19304187\n",
      "  0.11353916 -0.17923454]\n",
      "[-0.8431708  -0.58824825 -0.56400983 -0.53734868 -0.59358552 -0.47087767\n",
      " -0.33442203 -0.36273309]\n",
      "[0.22454833 0.90445258 2.25223324 0.51613608 0.33838663 1.56287095\n",
      " 0.49863985 0.38454518]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0, 0:8])\n",
    "print(X_train[0, 8:16])\n",
    "print(X_train[0, 16:24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classical ML Models\n",
    "\n",
    "Below we explore 10 classical machine learning models applied to the EEG dataset. All models use the same train/test split and reshaped feature matrix as the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEFAULT_THR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6459330143540671\n",
      "F1 score: 0.6\n",
      "Accuracy score: 0.6\n",
      "Precision score: 0.47368421052631576\n",
      "Recall score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "preds = log_reg.predict(X_test)\n",
    "binary_preds = (preds > DEFAULT_THR).astype(\"int\")\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc_score(y_true=y_test, y_score=preds)}\")\n",
    "print(f\"F1 score: {f1_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Precision score: {precision_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Recall score: {recall_score(y_true=y_test, y_pred=binary_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6722488038277513\n",
      "F1 score: 0.6206896551724138\n",
      "Accuracy score: 0.6333333333333333\n",
      "Precision score: 0.5\n",
      "Recall score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge = RidgeClassifier()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "preds = ridge.predict(X_test)\n",
    "binary_preds = (preds > DEFAULT_THR).astype(\"int\")\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc_score(y_true=y_test, y_score=preds)}\")\n",
    "print(f\"F1 score: {f1_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Precision score: {precision_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Recall score: {recall_score(y_true=y_test, y_pred=binary_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6602870813397128\n",
      "F1 score: 0.5833333333333334\n",
      "Accuracy score: 0.6666666666666666\n",
      "Precision score: 0.5384615384615384\n",
      "Recall score: 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "preds = sgd.predict(X_test)\n",
    "binary_preds = (preds > DEFAULT_THR).astype(\"int\")\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc_score(y_true=y_test, y_score=preds)}\")\n",
    "print(f\"F1 score: {f1_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Precision score: {precision_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Recall score: {recall_score(y_true=y_test, y_pred=binary_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare reshaped and scaled data\n",
    "# X_train, y_train = reshape_dataset(train)\n",
    "# X_test, y_test = reshape_dataset(test)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "The Support Vector Machine is a supervised learning algorithm that tries to find the best decision boundary (hyperplane) that separates different classes with the maximum margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6722488038277513\n",
      "F1 score: 0.6206896551724138\n",
      "Accuracy score: 0.6333333333333333\n",
      "Precision score: 0.5\n",
      "Recall score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC(kernel='rbf', probability=True, random_state=SEED)\n",
    "model_svm.fit(X_train, y_train)\n",
    "binary_preds = model_svm.predict(X_test)\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc_score(y_true=y_test, y_score=binary_preds)}\")\n",
    "print(f\"F1 score: {f1_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Accuracy score: {accuracy_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Precision score: {precision_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "print(f\"Recall score: {recall_score(y_true=y_test, y_pred=binary_preds)}\")\n",
    "\n",
    "# print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "A Decision Tree splits the data into branches to make decisions based on feature values. It is easy to interpret and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65        19\n",
      "           1       0.47      0.64      0.54        11\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.61      0.59        30\n",
      "weighted avg       0.64      0.60      0.61        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier(random_state=SEED)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that uses multiple decision trees and combines their outputs to improve performance and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.56      0.82      0.67        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.71      0.72      0.70        30\n",
      "weighted avg       0.75      0.70      0.71        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=SEED)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (k-NN)\n",
    "\n",
    "K-NN is a non-parametric method that classifies a data point based on how its neighbors are classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        19\n",
      "           1       0.35      0.55      0.43        11\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.48      0.48      0.46        30\n",
      "weighted avg       0.52      0.47      0.47        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, y_train)\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Gradient Boosting builds an ensemble of weak learners (usually decision trees) in a stage-wise manner to minimize a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.56      0.82      0.67        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.71      0.72      0.70        30\n",
      "weighted avg       0.75      0.70      0.71        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_gb = GradientBoostingClassifier(random_state=SEED)\n",
    "model_gb.fit(X_train, y_train)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "Naive Bayes uses Bayes' Theorem assuming independence between features. It's simple and works surprisingly well for many problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        19\n",
      "           1       0.69      1.00      0.81        11\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.84      0.87      0.83        30\n",
      "weighted avg       0.89      0.83      0.84        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)\n",
    "\n",
    "MLP is a type of neural network composed of layers of nodes. It can learn complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69        19\n",
      "           1       0.50      0.64      0.56        11\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.62      0.63      0.62        30\n",
      "weighted avg       0.66      0.63      0.64        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=SEED)\n",
    "model_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = model_mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a pipeline all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (RBF Kernel) Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.65        19\n",
      "           1       0.50      0.82      0.62        11\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.67      0.67      0.63        30\n",
      "weighted avg       0.71      0.63      0.64        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.56      0.82      0.67        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.71      0.72      0.70        30\n",
      "weighted avg       0.75      0.70      0.71        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "K-Nearest Neighbors Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.16      0.26        19\n",
      "           1       0.38      0.91      0.54        11\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.57      0.53      0.40        30\n",
      "weighted avg       0.62      0.43      0.36        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "Gradient Boosting Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.56      0.82      0.67        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.71      0.72      0.70        30\n",
      "weighted avg       0.75      0.70      0.71        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "Gaussian Naive Bayes Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        19\n",
      "           1       0.69      1.00      0.81        11\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.84      0.87      0.83        30\n",
      "weighted avg       0.89      0.83      0.84        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "Decision Tree Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65        19\n",
      "           1       0.47      0.64      0.54        11\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.61      0.59        30\n",
      "weighted avg       0.64      0.60      0.61        30\n",
      "\n",
      "------------------------------------------------------------\n",
      "MLP (Neural Net) Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73        19\n",
      "           1       0.56      0.82      0.67        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.71      0.72      0.70        30\n",
      "weighted avg       0.75      0.70      0.71        30\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_train, y_train = reshape_dataset(train)\n",
    "X_test, y_test = reshape_dataset(test)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'SVM (RBF Kernel)': SVC(kernel='rbf', probability=True, random_state=SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=SEED),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=SEED),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=SEED),\n",
    "    'MLP (Neural Net)': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=SEED)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"{name} Results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n",
    "    results.append((name, acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.836139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.705051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.705051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP (Neural Net)</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.705051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (RBF Kernel)</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.636188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.607240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.363416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  F1 Score\n",
       "0  Gaussian Naive Bayes  0.833333  0.836139\n",
       "1         Random Forest  0.700000  0.705051\n",
       "2     Gradient Boosting  0.700000  0.705051\n",
       "3      MLP (Neural Net)  0.700000  0.705051\n",
       "4      SVM (RBF Kernel)  0.633333  0.636188\n",
       "5         Decision Tree  0.600000  0.607240\n",
       "6   K-Nearest Neighbors  0.433333  0.363416"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Score'])\n",
    "results_df.sort_values(by='F1 Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
